{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2913bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import allel\n",
    "\n",
    "from utils.prepare_data import read_data, save_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "083e12fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = allel.read_vcf(snakemake.input[\"vcf\"])\n",
    "sample_size = len(data[\"samples\"])*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c111cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b87de850",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = list()\n",
    "\n",
    "for position, haps in zip(data['variants/POS'], data['calldata/GT']):\n",
    "    genotypes = haps.ravel()\n",
    "    records.append((position, genotypes.sum(), len(genotypes), 1))\n",
    "    \n",
    "sf_data = pd.DataFrame.from_records(records, columns=['position', 'x', 'n', 'folded'])\n",
    "save_data(sf_data, snakemake.output[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb81fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs = read_data(snakemake.input[\"sfs\"])\n",
    "\n",
    "# This is a janky way of going from a SFS of sample size 220 to sample size 216\n",
    "# Technically, there's a real downsampling solution in dadi\n",
    "sfs = sfs.loc[(sfs.num_alternate > 0) & (sfs.num_alternate < sample_size)]\n",
    "\n",
    "# Now let's fold this thing\n",
    "folded = sfs.assign(num_derived = np.minimum(sfs.num_alternate, sample_size - sfs.num_alternate))\n",
    "folded = pd.DataFrame(folded.groupby('num_derived').num_sites.sum()).reset_index()\n",
    "folded = pd.DataFrame({\n",
    "    'num_minor': folded.num_derived,\n",
    "    'num_sites': folded.num_sites,\n",
    "    'prop_num_sites': folded.num_sites/folded.num_sites.sum()\n",
    "})\n",
    "# Add a row for monomorphic sites with 0 minor alleles\n",
    "monomorphic = pd.DataFrame({'num_minor': 0, 'prop_num_sites': 0, 'num_sites': 0}, index=[-1])\n",
    "sfs_result = pd.concat([monomorphic, folded]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb8ad9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_result[['num_minor', 'prop_num_sites']].to_csv(snakemake.output[\"sfs\"], header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caabd77b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
